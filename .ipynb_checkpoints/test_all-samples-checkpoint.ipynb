{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix,coo_matrix\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "from scipy.linalg import svd\n",
    "from numpy import linalg as LA\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import glob\n",
    "from random import randint\n",
    "import umap\n",
    "import kmapper as km\n",
    "import networkx as nx\n",
    "from community import best_partition # this is not part of networkx\n",
    "import os.path\n",
    "\n",
    "def convertNansToZeros(ma):\n",
    "    nan_elements = np.flatnonzero(np.isnan(ma.data))\n",
    "    if len(nan_elements) > 0:\n",
    "        ma.data[nan_elements] = 0\n",
    "    return ma\n",
    "\n",
    "def convertInfsToZeros(ma):\n",
    "    inf_elements = np.flatnonzero(np.isinf(ma.data))\n",
    "    if len(inf_elements) > 0:\n",
    "        ma.data[inf_elements] = 0\n",
    "    return ma\n",
    "\n",
    "def usvd(df):\n",
    "    data = df.fillna(0).values\n",
    "    '''rescale observed data to (-1,1) range and output the new matrix z'''\n",
    "    i = np.nonzero(data)[0]\n",
    "    j = np.nonzero(data)[1]\n",
    "    x = data[np.nonzero(data)]\n",
    "    a = x.min()\n",
    "    b = x.max()\n",
    "    x = (x - (a+b)*0.5)/((b-a)*0.5)\n",
    "    z = csc_matrix((x,(i,j)), data.shape).todense()\n",
    "    '''svd'''\n",
    "    u, s, vt = svd(z,check_finite=True,full_matrices=False)\n",
    "    '''truncate svd'''\n",
    "    p = np.count_nonzero(z)*1.0/z.size # probability estimated from data pattern\n",
    "    threshold = 2.01*np.sqrt(p*max(z.shape)) # threshold obtained by usvd paper\n",
    "    ix = np.where( s > threshold )\n",
    "    k = ix[0].max()+1\n",
    "    w = np.dot(u[:,:k], np.dot(np.diag(s[:k]), vt[:k,:]))\n",
    "    '''clean'''\n",
    "    w[w < -1] = -1\n",
    "    w[w > 1] = 1\n",
    "    w = w*(b-a)*0.5+(a+b)*0.5\n",
    "    new_df = pd.DataFrame(w,index=df.index,columns=df.columns)\n",
    "    return new_df, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "datadir = '/home/garner1/Work/dataset/SSF/prostate-twelve/'\n",
    "allFiles = glob.glob(datadir + \"/*.tsv\")\n",
    "\n",
    "list_ = []\n",
    "\n",
    "for filename in allFiles:\n",
    "    frame = pd.read_csv(filename, sep='\\t', header=0, index_col=0) # read the gene X position count-matrix  \n",
    "    frameNorm = frame.div( frame.sum(axis=0)+1, axis=1 ) # to probability\n",
    "    list_.append( frameNorm.transpose() ) # position X genes\n",
    "\n",
    "'''\n",
    "Combine DataFrame objects with overlapping columns and return everything. \n",
    "Columns outside the intersection will be filled with NaN values.\n",
    "'''\n",
    "df = pd.concat(list_, axis = 0,join=\"outer\",ignore_index=True,sort=True).fillna(0) \n",
    "# df, k = usvd(df)\n",
    "# print df.shape, k\n",
    "\n",
    "data = df.values # position X genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Initialize'''\n",
    "mapper = km.KeplerMapper(verbose=1)\n",
    "metric = 'euclidean'\n",
    "'''Fit to and transform the data'''\n",
    "n_components = 3\n",
    "random_state = 157\n",
    "projected_data = mapper.fit_transform(data, \n",
    "                                      projection=umap.UMAP(n_neighbors=15,min_dist=0.1,\n",
    "                                                            n_components=n_components,\n",
    "                                                            metric=metric,\n",
    "                                                            random_state=random_state))\n",
    "\n",
    "'''Create dictionary called 'graph' with nodes, edges and meta-information'''\n",
    "nr_cubes = 10\n",
    "graph = mapper.map(projected_data, data,clusterer=DBSCAN(eps=0.5, \n",
    "                                                         min_samples=1, \n",
    "                                                         metric=metric),\n",
    "                   coverer=km.Cover(nr_cubes=nr_cubes, overlap_perc=0.5))\n",
    "\n",
    "'''Visualize it'''\n",
    "mapper.visualize(graph, path_html=str(metric)+\".UMAP.cubes\"+str(nr_cubes)+\".components\"+str(n_components)+\".rndstate\"+str(random_state)+\"_mapper_output.html\",title='all samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Visualize UMAP projection'''\n",
    "reducer = umap.UMAP(n_neighbors=15,min_dist=0.1,n_components=2,\n",
    "                    metric=metric,random_state=random_state)\n",
    "embedding = reducer.fit_transform(data)\n",
    "plt.figure()\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Build the network'''\n",
    "net = km.to_networkx(graph)\n",
    "print nx.info(net)\n",
    "spring_pos = nx.spring_layout(net)\n",
    "\n",
    "A = nx.adjacency_matrix(net)\n",
    "\n",
    "'''Create network layout for visualizations'''\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "nx.draw_networkx(net, pos = spring_pos, with_labels = False, node_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Partition the network'''\n",
    "parts = best_partition(net)\n",
    "values = [parts.get(node) for node in net.nodes()]\n",
    "\n",
    "'''Create network layout for visualizations'''\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "nx.draw_networkx(net, pos = spring_pos, cmap = plt.get_cmap(\"jet\"), \n",
    "                 node_color = values, node_size = 10, with_labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Get all the nodes in a module'''\n",
    "groups = []\n",
    "for value in set(parts.values()):\n",
    "    value_keys = [node for node in parts.keys() if value == parts[node]]\n",
    "    groups.append(value_keys) \n",
    "\n",
    "'''Get the entire space-profile'''\n",
    "summa = dfnorm.sum(axis=0) # sum over all genes (to get 1!!!)\n",
    "spatialCoord = [w.split('x') for w in list(summa.index.values)]\n",
    "spatialCoord = [map(int,pairs) for pairs in spatialCoord]\n",
    "i = [l[0] for l in spatialCoord]\n",
    "j = [l[1] for l in spatialCoord]\n",
    "maxi = max(i)+1\n",
    "maxj = max(j)+1\n",
    "data = summa.values\n",
    "mat_global = coo_matrix((data, (i, j)), [maxi, maxj]).todense()\n",
    "\n",
    "'''Plot the spatial projection of the modules'''\n",
    "ind = 0 \n",
    "for group in range(len(groups)):\n",
    "\n",
    "    spots = [graph['nodes'][node] for node in groups[group]]\n",
    "    l = list(set([item for sublist in spots for item in sublist]))\n",
    "    \n",
    "    newdf = dfnorm.transpose().iloc[l,:].transpose()\n",
    "    summa = newdf.sum(axis=0)\n",
    "\n",
    "    spatialCoord = [w.split('x') for w in list(summa.index.values)]\n",
    "    spatialCoord = [map(int,pairs) for pairs in spatialCoord]\n",
    "\n",
    "    i = [s[0] for s in spatialCoord]\n",
    "    j = [s[1] for s in spatialCoord]\n",
    "\n",
    "    if len(i) > 0:\n",
    "        ind += 1\n",
    "        plt.figure()\n",
    "        mat = coo_matrix((summa.values, (i, j)), [maxi, maxj]).todense()\n",
    "        mat = 2*mat_global - mat\n",
    "        cmap = sns.color_palette(\"husl\", 3)\n",
    "        sns.heatmap(mat,cmap=ListedColormap(['green', 'yellow', 'red']), annot=False)\n",
    "        plt.title(\"#profile: \"+str(ind)+\"; #spots: \"+str(len(l))+\"; #nodes: \"+str(len(spots)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Plot spatial distribution of RC for a given gene'''\n",
    "for gene in [\"SPON1 \",\"TFF3 \",\"SPINK1 \"]: # leave a space to make unique the name\n",
    "    getGene = df[df.index.str.contains(gene)==True].transpose()\n",
    "\n",
    "    spatialCoord = [w.split('x') for w in list(getGene.index.values)]\n",
    "    spatialCoord = [map(int,pairs) for pairs in spatialCoord]\n",
    "\n",
    "    i = [s[0] for s in spatialCoord]\n",
    "    j = [s[1] for s in spatialCoord]\n",
    "\n",
    "    plt.figure()\n",
    "    mat = coo_matrix((getGene.values.ravel(), (i, j)), [maxi, maxj]).todense()\n",
    "    sns.heatmap(mat, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat_global,cmap=ListedColormap(['green', 'yellow', 'red']), annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = './matglobalep11.npz'\n",
    "np.savez(outfile, mat_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
